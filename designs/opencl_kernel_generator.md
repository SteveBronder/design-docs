- Feature Name: opencl_kernel_generator
- Start Date: 2019-10-21
- RFC PR: (leave this empty)
- Stan Issue: (leave this empty)

# Summary
[summary]: #summary

Define operators and functions on matrix_cl that will use 
[expresson templates](https://en.wikipedia.org/wiki/Expression_templates) 
to construct expressions. When assigned to a matrix_cl an expression will generate an 
OpenCL kernel in a JIT fashion and execute it to calculate the result of the expression.

# Motivation
[motivation]: #motivation

Using expression templates is much simpler than writing OpenCL kernels by hand and it does 
not require knowledge of OpenCL and parallel programming.

Using one kernel for multiple operations is faster than using one kernel per operation. Each 
kernel must load its arguments from global global GPU memory and store results back. Memory 
transfers are relatively slow compared to calculations. In case of simple kernels majority 
of kernel execution time is spent for memory transfers. Kernel generator can generate a single 
kernel from a sequence of operations and is therefore more performant than using one predefined
kernel for each operation.

Any operation that requires no communication between threads can be implemented in kernel 
generator. While that means not any kernel can be rewritten with kernel generator, many, if 
not most of ones needed in Stan Math should qualify. 

# Explanation
[guide-level-explanation]: #explanation

A kernel generator expression consists of operations, for example addition, exponentiation, 
transposition. While not operations in mathematical sense, accesses to matrices and scalars are also operations 
in kernel generator.

Each operation is implemented as a templated class. When instantiated those templates are given
types of the subexpressions that are arguments to the particular operation. User-facing 
functions are used to simplify construction of operations, since class templates can not 
be deduced in C++14. 

Each operation object is responsible for generating kernel code for the operation it 
represents. Each operation selects a unique variable name and generates kernel code that 
declares a variable and assigns the result of the operation to it. If the operation has any
arguments that are operations themselves it can access variables they use for their results.
If the operation needs any other data it can specify kernel arguments. For example an operation 
that accesses a matrix might need a pointer to matrix data and size of the matrix.

Some operations can also be used in expressions that are assigned to. The most basic case 
is access to matrix - i.e. storing the result of a kernel. Another example is matrix sub block 
operation Such operations can also generate
kernel code for appearing on the left-hand-side of assignment. While the code is different the
process of generating it is similar to generating code for an operation on the right-hand side 
of an assignment.

Kernel generator expressions can consist of operations, matrices and scalars. Operations have
appropriate methods for constructing kernel source. Matrices and scalars on the other hand do 
not. So they need to be wrapped in appropriate wrapper that is an operation whenever they are
used in a kernel generator expression.

If an expression is used multiple times the kernel associated with it should be cached. So 
regeneration and recompilation of kernel is not necessary at every time an expression is 
evaluated. Instead kernel is generated only at first use. Cached kernel can also be reused
between instances of expressions consisting of same operands, but operating on different data, 
even if the matrices have different sizes.

Caching is global within a program. In other words cached kernels are only deleted when the
program using them is terminated. Trough templated classes we achieve that every possible expression
has different type. So any kernel generated by kernel generator can be uniquely identified by 
a pair that includes type of the expression ant the type of the result. That allows us not to use
a map or a similar object to implement cache. Instead cached kernel can be a static member of
a struct that is templated by both types of the expression and the result.

# Example and reference level explanantion

```c++
matrix_cl<double> a, b;
double c;
matrix_cl<double> d = c * (a + b);
```

In this example `a` and `b` are first wrapped in a matrix access operation called `load_`. 
It is templated with the type of the type of argument, which can be either value or reference
 (the class implements perfect forwarding). In this example both `a` and `b` are lvalues so we
 get `load_<matrix_cl<double>&>` in both cases. This happens within
the operator+. This operator returns an addition object that references its parameters - 
its type is `addition_<load_<matrix_cl<double>&>, load_<matrix_cl<double>&>>`. 

operator* wraps scalar in scalar accessing operation that is templated with the type of the scalar
 (`scalar_<double>`) and constructs element-wise multiplication object that 
references that and the addition as its arguments - resulting in an object of type
`elewise_multiplication_<scalar_<double>, addition_<load_<matrix_cl<double>&>, load_<matrix_cl<double>&>>>`. 

When assigned to a matrix the expression 
generates the opencl kernel. Internally `d` is also wrapped into `load_<matrix_cl<double>&>`. 
Matrix access operations generate code for loading matrix elements from
 global memory. Addition generates code for adding them together.
Multiplication multiplies the result with the scalar. `d`'s wrapper generates code for storing the 
back to global memory. 

After the kernel is compiled it is cached into 
`static operation<elewise_multiplication_<scalar_<double>, addition_<load_<matrix_cl<double>&>, load_<matrix_cl<double>&>>>>::cache<load<matrix_cl<double>&>::kernel`

# Drawbacks
[drawbacks]: #drawbacks

Even with caching each kernel must be compiled the first time it is used. If many kernels are used and each only once, long compilations times could make this slower than one kernel per operation. This is not an issue in Stan, since many leapfrog steps are executed.

# Prior art
[prior-art]: #prior-art

Expression templates are widely used in Eigen.

Tensorflow XLA is experimental kernel fusion feature of Tensorflow.
